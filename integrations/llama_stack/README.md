# llama-stack-haystack

[![PyPI - Version](https://img.shields.io/pypi/v/llama-stack-haystack.svg)](https://pypi.org/project/llama-stack-haystack)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/llama-haystack.svg)](https://pypi.org/project/llama-stack-haystack)

- [Integration page](https://haystack.deepset.ai/integrations/llama_stack)
- [Changelog](https://github.com/deepset-ai/haystack-core-integrations/blob/main/integrations/llama_stack/CHANGELOG.md)

---

## Contributing

Refer to the general [Contribution Guidelines](https://github.com/deepset-ai/haystack-core-integrations/blob/main/CONTRIBUTING.md).

To run integration tests locally, you need to run Ollama and the Llama Stack Server. Refer to the [workflow file](https://github.com/deepset-ai/haystack-core-integrations/blob/main/.github/workflows/llama_stack.yml) for more details.