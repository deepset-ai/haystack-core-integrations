# SPDX-FileCopyrightText: 2024-present deepset GmbH <info@deepset.ai>
#
# SPDX-License-Identifier: Apache-2.0
from typing import Any, Dict, List, Optional, Type, Union

import requests
from haystack import component, default_from_dict, default_to_dict
from haystack.utils.auth import Secret, deserialize_secrets_inplace

from .models import NvidiaGeneratorModel
from .providers import ModelProvider, NvidiaProvider

REQUESTS_TIMEOUT = 30

FUNCTIONS_ENDPOINT = "https://api.nvcf.nvidia.com/v2/nvcf/functions"

MODEL_PROVIDERS: Dict[NvidiaGeneratorModel, Type[ModelProvider]] = {
    NvidiaGeneratorModel.NV_LLAMA2_RLHF_70B: NvidiaProvider,
    NvidiaGeneratorModel.STEERLM_LLAMA_70B: NvidiaProvider,
    NvidiaGeneratorModel.NEMOTRON_STEERLM_8B: NvidiaProvider,
    NvidiaGeneratorModel.NEMOTRON_QA_8B: NvidiaProvider,
}


@component
class NvidiaGenerator:
    """
    TODO
    """

    def __init__(
        self,
        model: Union[str, NvidiaGeneratorModel],
        api_key: Secret = Secret.from_env_var("NVIDIA_API_KEY"),
        model_arguments: Optional[Dict[str, Any]] = None,
    ):
        """
        Create a NvidiaGenerator component.

        :param model:
            Name of the model to use for text generation.
            See the [Nvidia catalog](https://catalog.ngc.nvidia.com/ai-foundation-models) to know the  supported models.
        :param api_key:
            Nvidia API key to use for authentication.
        :param model_arguments:
            Additional arguments to pass to the model provider. Different models accept different arguments.
            Search your model in the [Nvidia catalog](https://catalog.ngc.nvidia.com/ai-foundation-models)
            to know the supported arguments.

        :raises ValueError: If `model` is not supported.
        """
        self._model = model
        self._api_key = api_key
        self._model_arguments = model_arguments or {}

        # We use a Session to make requests as it's a bit faster as it reuses the same connection
        self._session = requests.Session()
        self._session.headers.update(
            {
                "Authorization": f"Bearer {self._api_key.resolve_value()}",
                "Content-Type": "application/json",
            }
        )

        if self._model not in MODEL_PROVIDERS:
            models = ", ".join(e.value for e in NvidiaGeneratorModel)
            msg = f"Model {self._model} is not supported, available models are: {models}"
            raise ValueError(msg)

        model_info = self._model_info()
        provider = MODEL_PROVIDERS[self._model]
        self._model_provider = provider(session=self._session, model_id=model_info["id"], **self._model_arguments)

    def to_dict(self) -> Dict[str, Any]:
        """
        Serializes the component to a dictionary.

        :returns:
            Dictionary with serialized data.
        """
        return default_to_dict(
            self, model=str(self._model), api_key=self._api_key.to_dict(), model_arguments=self._model_arguments
        )

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "NvidiaGenerator":
        """
        Deserializes the component from a dictionary.

        :param data:
            Dictionary to deserialize from.
        :returns:
           Deserialized component.
        """
        init_params = data.get("init_parameters", {})
        deserialize_secrets_inplace(init_params, ["api_key"])
        return default_from_dict(cls, data)

    def _model_info(self) -> Dict[str, Any]:
        res = self._session.get(url=FUNCTIONS_ENDPOINT, timeout=REQUESTS_TIMEOUT)
        res.raise_for_status()
        for model in res.json()["functions"]:
            if model["name"] == self._model:
                return model
        msg = f"Model {self._model} is not supported"
        raise ValueError(msg)

    @component.output_types(replies=List[str], meta=List[Dict[str, Any]])
    def run(self, prompt: str):
        """
        Queries the model with the provided prompt.

        :param prompt:
            Text to be sent to the generative model.
        :returns:
            A dictionary with the following keys:
            - "replies": replies generated by the model.
            - "meta": metadata for each reply.
        """
        return self._model_provider.send(messages=[{"role": "user", "content": prompt}])
